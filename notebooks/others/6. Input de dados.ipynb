{"cells":[{"cell_type":"markdown","metadata":{"id":"MkFiSSVXoj6o"},"source":["# Importing Deploy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dddVuZQANLcs"},"outputs":[],"source":["!pip install --upgrade scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m-370TIDpdC2"},"outputs":[],"source":["from joblib import load\n","import pandas as pd\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14724,"status":"ok","timestamp":1696531493613,"user":{"displayName":"Gabriel Pelinsari","userId":"09129859543646402177"},"user_tz":180},"id":"-tuk5tdgotNJ","outputId":"0d209b44-bf46-4578-ed82-d7d19daedc98"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1QgnJLMk3bYuzMRx8QN8KWp4eaFyCtX-Z\n","To: /content/df_final.csv\n","100% 5.63M/5.63M [00:00<00:00, 274MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1DBsgpSCfNvYo0NH2RVoO7XbCcrB8YZZ7\n","To: /content/RandomForestModel.joblib\n","100% 18.1M/18.1M [00:00<00:00, 84.6MB/s]\n"]}],"source":["!gdown 1QgnJLMk3bYuzMRx8QN8KWp4eaFyCtX-Z\n","!gdown 1DBsgpSCfNvYo0NH2RVoO7XbCcrB8YZZ7"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":567},"executionInfo":{"elapsed":586,"status":"error","timestamp":1696531494195,"user":{"displayName":"Gabriel Pelinsari","userId":"09129859543646402177"},"user_tz":180},"id":"nEeDSjguoRG6","outputId":"2bc7c175-e2d5-468f-a408-329e5ddd6927"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.3.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f73fc4ef0794>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/RandomForestModel.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/df_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n","\u001b[0;32m/usr/lib/python3.10/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mNDArrayWrapper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mcompatibility\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \"\"\"\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mUnpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# For backward compatibility, we support NDArrayWrapper objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0msetstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__setstate__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msetstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1718\u001b[0;31m             \u001b[0msetstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1719\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m         \u001b[0mslotstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree.__setstate__\u001b[0;34m()\u001b[0m\n","\u001b[0;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree._check_node_ndarray\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: node array from the pickle has an incompatible dtype:\n- expected: [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]\n- got     : {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}"]}],"source":["# Load a pre-trained Random Forest Classifier model from a joblib file named 'RandomForestModel.joblib'.\n","rf_loaded = load('/content/RandomForestModel.joblib')\n","\n","# Read a CSV file named 'df_final.csv' into a pandas DataFrame named 'df_final'.\n","df_final = pd.read_csv('/content/df_final.csv')"]},{"cell_type":"markdown","metadata":{"id":"t0VFODfLpBpV"},"source":["# Making the prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NnWF7of3LCRO"},"outputs":[],"source":["# Drop the 'Unnamed: 0' column from the DataFrame 'df_final' along the specified axis (column axis).\n","# The 'inplace=True' parameter means the DataFrame is modified in place, and no new DataFrame is returned.\n","df_final.drop('Unnamed: 0', axis=1, inplace=True)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"txL-Y99-v9Pe"},"outputs":[{"ename":"NameError","evalue":"name 'df_final' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Inteli\\Desktop\\Modulo 3\\grupo2\\notebooks\\others\\6. Input de dados.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Inteli/Desktop/Modulo%203/grupo2/notebooks/others/6.%20Input%20de%20dados.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X \u001b[39m=\u001b[39m df_final\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mchurn\u001b[39m\u001b[39m'\u001b[39m])\n","\u001b[1;31mNameError\u001b[0m: name 'df_final' is not defined"]}],"source":["# Create a new DataFrame 'X' by dropping the 'id' and 'churn' columns from the DataFrame 'df_final'.\n","X = df_final.drop(columns=['id', 'churn'])\n","\n","# Use the pre-trained Random Forest Classifier 'rf_loaded' to predict probabilities for the data in 'X'.\n","previsionRF = rf_loaded.predict_proba(X)\n","\n","# Initialize an empty list 'prob_predict' to store the predicted probabilities of churn.\n","prob_predict = []\n","\n","# Iterate through the predictions and extract the probability of churn (class 1) for each prediction.\n","for i in range(len(previsionRF)):\n","    prob_predict.append(previsionRF[i][1])\n"]},{"cell_type":"markdown","metadata":{"id":"K1eLKshMffik"},"source":["# Table merge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPCGmOxorBv8"},"outputs":[],"source":["# Create a new DataFrame 'df_prob' using the 'prob_predict' list.\n","df_prob = pd.DataFrame(prob_predict)\n","\n","# Create a DataFrame 'x' containing the data from DataFrame 'X'.\n","x = pd.DataFrame(X)\n","\n","# Create a DataFrame 'id_col' containing the 'id' column from 'df_final'.\n","id_col = pd.DataFrame(df_final['id'])\n","\n","# Concatenate 'id_col', 'x', and 'df_prob' along the columns (axis=1) to create 'df_final_s'.\n","df_final_s = pd.concat([id_col, x, df_prob], axis=1)\n","\n","# Retrieve the column names of 'df_final_s'.\n","df_final_s.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJ2Lk2txr6Dz"},"outputs":[],"source":["# fazendo a junção da coluna de classificação com o dataframe principal\n","df_final_s['Probabilidade Churn'] = df_prob\n","\n","# criando o dataframe final, que possuirá apenas a coluna de Storekeeper e a classificação da probabilidade de churn\n","df_final = df_final_s[['id', 'net_margin', 'price_p1_var', 'price_p1_fix', 'num_years_antig', 'cons_12m', 'consumption', 'Probabilidade Churn']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZNPdaStvHLo"},"outputs":[],"source":["df_final"]},{"cell_type":"markdown","metadata":{"id":"MkI8eOQvEE1n"},"source":["# Input de novos dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YfRwTL15EJiu"},"outputs":[],"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","if len(uploaded) > 0:\n","    nome_arquivo = list(uploaded.keys())[0]\n","\n","    print(f'Arquivo carregado: \"{nome_arquivo}\"')\n","else:\n","    print(\"Nenhum arquivo foi carregado.\")\n","    \n","\n","df_novo = pd.read_csv(f'/content/{nome_arquivo}')\n","\n","X_novo = df_novo.drop(columns=['id', 'churn'])\n","\n","X_novo\n","\n","X_novo.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1, inplace=True)\n","\n","new_previsionRF = rf_loaded.predict_proba(X_novo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCyFDEZFU5xB"},"outputs":[],"source":["# Initialize an empty list 'new_prob_predict' to store the predicted probabilities of churn.\n","new_prob_predict = []\n","\n","# Iterate through the predictions in 'new_previsionRF' and extract the probability of churn (class 1) for each prediction.\n","for i in range(len(new_previsionRF)):\n","    new_prob_predict.append(new_previsionRF[i][1])\n","\n","# Create a new DataFrame 'df_prob_novo' using the 'new_prob_predict' list.\n","df_prob_novo = pd.DataFrame(new_prob_predict)\n","\n","# Create a DataFrame 'x_novo' containing the data from DataFrame 'X_novo'.\n","x_novo = pd.DataFrame(X_novo)\n","\n","# Create a DataFrame 'id_col_nova' containing the 'id' column from 'df_novo'.\n","id_col_nova = pd.DataFrame(df_novo['id'])\n","\n","# Concatenate 'id_col_nova', 'x_novo', and 'df_prob_novo' along the columns (axis=1) to create 'df_final_novo'.\n","df_final_novo = pd.concat([id_col_nova, x_novo, df_prob_novo], axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_StBijlTU5xC"},"outputs":[],"source":["df_final_novo.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EudoWlgFU5xD"},"outputs":[],"source":["# Add a new column 'Probabilidade Churn' to 'df_final_novo' and populate it with the values from 'df_prob_novo'.\n","df_final_novo['Probabilidade Churn'] = df_prob_novo\n","\n","# Reorder the columns in 'df_final_novo' to include only selected columns.\n","df_final_novo = df_final_novo[['id', 'net_margin', 'price_p1_var', 'price_p1_fix', 'num_years_antig', 'cons_12m', 'consumption', 'Probabilidade Churn']]\n","\n","# Merge 'df_final_novo' with the original 'df_final' DataFrame based on the 'id' column using an inner join.\n","resultado = df_final_novo.merge(df_final, on='id', how='inner')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NB4e4nqbZtDu"},"outputs":[],"source":["resultado"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM/az6kc3+GU41WhwXOyiDD","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
